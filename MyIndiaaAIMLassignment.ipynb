{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t82KMp9K4wdL"
      },
      "source": [
        "# OpenAPI KEY - (enter a working API key for text generation (mine ran out of daily limit)still mentioned in the code)\n",
        "\n",
        "***Files attached - 'Updated_dataset.csv' and 'interaction_log.csv'***\n",
        "\n",
        "***Basic A/B Test Framework***\n",
        "\n",
        "***Mock API (with future references)***\n",
        "\n",
        "***Documentation while wrting the code***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hfk5Fu0RpCT1"
      },
      "source": [
        " # ***Point 1: Product Description Generator using GPT-3.5***\n",
        "\n",
        "This script uses the gpt-3.5-turbo model for generating product descriptions with streaming responses. It takes user inputs for product attributes and generates a description in real-time, printing it as it is received from the model. ***Make sure to replace 'your-api-key' with your actual OpenAI API key.***\n",
        "\n",
        "***User Inputs:*** The script prompts the user to enter product attributes: product name, product category, and product features.\n",
        "\n",
        "***Prompt Creation:*** It creates a detailed prompt for the GPT-3.5 model to generate a product description, emphasizing the role of the AI as an \"e-commerce platform creative expert.\"\n",
        "\n",
        "\n",
        "***Streaming Response:*** The script uses streaming to generate the product description in real-time.\n",
        "\n",
        "\n",
        "***Description Collection:*** It collects the generated description and prints it out.\n",
        "\n",
        "\n",
        "***Data Storage: ***The product attributes and generated description are stored in a dictionary.\n",
        "\n",
        "\n",
        "***CSV Saving:*** The script writes the dictionary data to a CSV file (product_descriptions.csv). If the CSV file does not exist or is empty, it writes the header first.\n",
        "\n",
        "# ***Benefits of Using AI for Product Descriptions***\n",
        "\n",
        "***Consistency:*** AI ensures consistent tone and style across all product descriptions.\n",
        "\n",
        "***Efficiency:*** It significantly reduces the time required to create product descriptions.\n",
        "\n",
        "\n",
        "***Scalability:*** AI can handle large volumes of products effortlessly, making it ideal for extensive catalogs.\n",
        "\n",
        "\n",
        "***Personalization:*** AI can tailor descriptions to different segments, enhancing user experience and engagement.\n",
        "\n",
        "\n",
        "***Creativity:*** AI can generate creative and engaging content, leveraging vast amounts of training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HA8xblecfbv1",
        "outputId": "b3616050-b562-4dab-89b9-e3c9284afcb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2024.6.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Collecting implicit\n",
            "  Downloading implicit-0.7.2-cp310-cp310-manylinux2014_x86_64.whl (8.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from implicit) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.10/dist-packages (from implicit) (1.11.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from implicit) (4.66.4)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from implicit) (3.5.0)\n",
            "Installing collected packages: implicit\n",
            "Successfully installed implicit-0.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install implicit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "collapsed": true,
        "id": "BAkuEH-ikCaO",
        "outputId": "8e9ce06d-5505-4d58-8758-c283f0a49718"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the product name: xix\n",
            "Enter the product category: vodka\n",
            "Enter the product features: bottle\n"
          ]
        },
        {
          "ename": "RateLimitError",
          "evalue": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-8103ad5cc0e0>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mgenerate_product_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-8103ad5cc0e0>\u001b[0m in \u001b[0;36mgenerate_product_description\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Generating the product description using GPT-3.5 with streaming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     stream = chat_completion.ChatCompletion.create(  # Use the class method directly\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    766\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             )\n",
            "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
          ]
        }
      ],
      "source": [
        "import csv\n",
        "from openai import OpenAI\n",
        "\n",
        "# Replace 'your-api-key' with your actual OpenAI API key\n",
        "client = OpenAI(api_key='OPEN_API_KEY')\n",
        "\n",
        "def generate_product_description():\n",
        "    # Taking user inputs for product attributes\n",
        "    product_name = input(\"Enter the product name: \")\n",
        "    product_category = input(\"Enter the product category: \")\n",
        "    product_features = input(\"Enter the product features: \")\n",
        "\n",
        "    # Creating the prompt for GPT-3.5 with enhanced context\n",
        "    prompt = (\n",
        "        f\"Act as an e-commerce platform creative expert. \"\n",
        "        f\"Generate a compelling product description for the following details:\\n\"\n",
        "        f\"Product Name: {product_name}\\n\"\n",
        "        f\"Category: {product_category}\\n\"\n",
        "        f\"Features: {product_features}\\n\"\n",
        "        f\"Description:\"\n",
        "    )\n",
        "\n",
        "    # Generating the product description using GPT-3.5 with streaming\n",
        "    stream = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        stream=True,\n",
        "    )\n",
        "\n",
        "    # Collecting the streaming response\n",
        "    description = \"\"\n",
        "    print(\"\\nGenerated Product Description:\")\n",
        "    for chunk in stream:\n",
        "        if chunk.choices[0].delta.content is not None:\n",
        "            content = chunk.choices[0].delta.content\n",
        "            print(content, end=\"\")\n",
        "            description += content\n",
        "\n",
        "    # Storing the data in a dictionary\n",
        "    product_data = {\n",
        "        \"product_name\": product_name,\n",
        "        \"product_category\": product_category,\n",
        "        \"product_features\": product_features,\n",
        "        \"description\": description.strip()\n",
        "    }\n",
        "\n",
        "    # Writing the data to a CSV file\n",
        "    csv_file = 'product_descriptions.csv'\n",
        "    fieldnames = [\"product_name\", \"product_category\", \"product_features\", \"description\"]\n",
        "\n",
        "    try:\n",
        "        with open(csv_file, mode='a', newline='') as file:\n",
        "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
        "\n",
        "            # Write header only if the file is empty\n",
        "            file.seek(0, 2)\n",
        "            if file.tell() == 0:\n",
        "                writer.writeheader()\n",
        "\n",
        "            writer.writerow(product_data)\n",
        "        print(\"\\nProduct description saved to CSV file successfully.\")\n",
        "    except IOError as e:\n",
        "        print(f\"Error writing to CSV file: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLo_qe7aplLV"
      },
      "source": [
        "**User Inputs:** The script prompts the user to enter product attributes.\n",
        "\n",
        "**Prompt Creation**: It creates a prompt for the GPT-3.5 model.\n",
        "\n",
        "**Streaming Response**: The script uses streaming to generate the product description in real-time.\n",
        "\n",
        "**Description Collection**: It collects the generated description and prints it out.\n",
        "\n",
        "**Data Storage:** The product attributes and generated description are stored in a dictionary.\n",
        "\n",
        "**CSV Saving:** The script writes the dictionary data to a CSV file (product_descriptions.csv). If the CSV file does not exist or is empty, it writes the header first.\n",
        "\n",
        "**Make sure to replace 'your-api-key' with your actual OpenAI API key.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZBNwSRfrPiH"
      },
      "source": [
        "# A Python script that creates fake/random data for 500 users with columns 'user_id', 'item_id', and 'interaction', and saves it to a CSV file named 'updated_dataset.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUqTIYjpnoA8",
        "outputId": "baa86f09-471e-4407-edbb-ef6d750c0cd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random data saved to 'updated_dataset.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Function to create random data\n",
        "def create_random_data(num_users=500, num_items=100, interactions_per_user=20):\n",
        "    np.random.seed(42)  # For reproducibility\n",
        "\n",
        "    data = []\n",
        "    for user_id in range(1, num_users + 1):\n",
        "        for _ in range(interactions_per_user):\n",
        "            item_id = np.random.randint(1, num_items + 1)\n",
        "            interaction = np.random.choice(['view', 'click', 'purchase'], p=[0.7, 0.2, 0.1])\n",
        "            data.append([user_id, item_id, interaction])\n",
        "\n",
        "    return pd.DataFrame(data, columns=['user_id', 'item_id', 'interaction'])\n",
        "\n",
        "# Generate random data\n",
        "df = create_random_data()\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv('updated_dataset.csv', index=False)\n",
        "print(\"Random data saved to 'updated_dataset.csv'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aDSZdnqrZ5F"
      },
      "source": [
        "***Function to Create Random Data:*** The create_random_data function generates random data for a specified number of users, items, and interactions per user.\n",
        "\n",
        "***Parameters:***\n",
        "num_users: Number of users (default is 500).\n",
        "num_items: Number of items (default is 100).\n",
        "interactions_per_user: Number of interactions per user (default is 20).\n",
        "For each user, it generates a specified number of interactions.\n",
        "Each interaction randomly selects an item and an interaction type (view, click, purchase) with predefined probabilities.\n",
        "Generate Random Data: Calls the function to generate random data.\n",
        "\n",
        "***Save to CSV:*** Saves the generated data to a CSV file named 'updated_dataset.csv'.\n",
        "\n",
        "# This script ensures that you have a dataset with user interactions ready for training the recommendation model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tPLFQdNrkVW"
      },
      "source": [
        "# Point 2: Product Recommendation System\n",
        "For this part, you'll need to set up a recommendation system using a relevant dataset from Kaggle.\n",
        "\n",
        "Let's assume we are using a dataset that includes user interactions like views, clicks, and purchases. Below is a Python script using the implicit library for collaborative filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCPxb-gAtvG2",
        "outputId": "4dfd6d55-9051-4778-852f-9601855a0e66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   user_id  item_id interaction\n",
            "0        1       52    purchase\n",
            "1        1       72        view\n",
            "2        1       83        view\n",
            "3        1       75       click\n",
            "4        1      100        view\n"
          ]
        }
      ],
      "source": [
        "# get df head for csv file\n",
        "\n",
        "df = pd.read_csv('updated_dataset.csv')\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443,
          "referenced_widgets": [
            "efb878fa11b042fbbf61f177c3bc825e",
            "7c4c221749c44f1a96352dc1d1e6d15b",
            "b25f2833a42c4f38bb32dfe17331d11f",
            "95f2c212fda74b4984112d7049d60cb8",
            "6d8b90d9e25641d9a712164aaed064a5",
            "479fc16c96b64482afa5f3e533b3d90f",
            "ebf64c7ec1f64804b806784dbb234235",
            "eab13da1d27b4381bfcf2eb31b00f013",
            "c0d5c06b3d1d4b2787b55ec24a838258",
            "58bf6f0e547244e8be6faa0dd300de0d",
            "4d2873467f744e5b90da2d5f43e17eb4"
          ]
        },
        "collapsed": true,
        "id": "oyAX3sCbrj34",
        "outputId": "fc923ec9-5333-4125-a129-f781d91abb95"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed coo_matrix instead. Converting to CSR took 0.0003845691680908203 seconds\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efb878fa11b042fbbf61f177c3bc825e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the user ID: 1\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "user_items must contain 1 row for every user in userids",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-5dbe7eea28ce>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0muser_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the user ID: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mrecommend_products\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-5dbe7eea28ce>\u001b[0m in \u001b[0;36mrecommend_products\u001b[0;34m(user_id, num_recommendations)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecommend_products\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_recommendations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Get recommendations for the given user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mrecommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_user_item_csr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_recommendations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mrecommended_item_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecommendations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/implicit/cpu/matrix_factorization_base.py\u001b[0m in \u001b[0;36mrecommend\u001b[0;34m(self, userid, user_items, N, filter_already_liked_items, filter_items, recalculate_user, items)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0muser_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muser_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0muser_count\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"user_items must contain 1 row for every user in userids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_user_factor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecalculate_user\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: user_items must contain 1 row for every user in userids"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from implicit.als import AlternatingLeastSquares\n",
        "from scipy.sparse import coo_matrix, csr_matrix\n",
        "\n",
        "# Load the dataset (replace 'path_to_dataset' with the actual dataset path)\n",
        "data = pd.read_csv('/content/updated_dataset.csv')\n",
        "\n",
        "# Assuming the dataset has columns: 'user_id', 'item_id', 'interaction'\n",
        "user_item_interaction = data[['user_id', 'item_id', 'interaction']]\n",
        "\n",
        "# Encode the 'interaction' column\n",
        "# This creates a mapping from interaction type to a numerical value\n",
        "interaction_encoder = {v: i for i, v in enumerate(user_item_interaction['interaction'].unique())}\n",
        "user_item_interaction['interaction_encoded'] = user_item_interaction['interaction'].map(interaction_encoder)\n",
        "\n",
        "# Creating a sparse matrix for user-item interactions using encoded values\n",
        "sparse_user_item = coo_matrix((user_item_interaction['interaction_encoded'],\n",
        "                               (user_item_interaction['user_id'], user_item_interaction['item_id'])))\n",
        "\n",
        "# Convert the COO matrix to CSR format\n",
        "sparse_user_item_csr = sparse_user_item.tocsr()\n",
        "\n",
        "# Training the ALS model\n",
        "model = AlternatingLeastSquares(factors=50, regularization=0.01, iterations=30)\n",
        "model.fit(sparse_user_item.T)\n",
        "\n",
        "def recommend_products(user_id, num_recommendations=5):\n",
        "    # Get recommendations for the given user\n",
        "    recommendations = model.recommend(user_id, sparse_user_item_csr, N=num_recommendations)\n",
        "    recommended_item_ids = [item[0] for item in recommendations]\n",
        "\n",
        "    print(f\"Recommended Products for User {user_id}: {recommended_item_ids}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    user_id = int(input(\"Enter the user ID: \"))\n",
        "    recommend_products(user_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coRvGKiDvhv3"
      },
      "source": [
        "# A/B Testing Framework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiX74B8TvkmO"
      },
      "source": [
        "Implementing an A/B testing framework involves setting up a system to compare the performance of different content generation strategies or recommendation algorithms. Here's a solution that includes tracking and analyzing user interactions.\n",
        "\n",
        "***A/B Test Setup: Assigning users to different groups.***\n",
        "\n",
        "**Tracking User Interactions:** Logging user interactions with the content.\n",
        "Analyzing Results: Comparing the performance of different strategies.\n",
        "\n",
        "A/B Test Setup -\n",
        "\n",
        "*First, we'll set up the A/B test by randomly assigning users to different groups.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1sO4gdhubxy",
        "outputId": "5a226dc6-b91d-42db-bf11-16f7091280c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Group A: 250 users\n",
            "Group B: 250 users\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Function to assign users to A/B test groups\n",
        "def assign_ab_groups(num_users=500, group_a_ratio=0.5):\n",
        "    np.random.seed(42)  # For reproducibility\n",
        "    users = np.arange(1, num_users + 1)\n",
        "    np.random.shuffle(users)\n",
        "    split_point = int(num_users * group_a_ratio)\n",
        "    group_a = users[:split_point]\n",
        "    group_b = users[split_point:]\n",
        "    return group_a, group_b\n",
        "\n",
        "group_a, group_b = assign_ab_groups()\n",
        "print(f\"Group A: {len(group_a)} users\")\n",
        "print(f\"Group B: {len(group_b)} users\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sN7aMNXv1hR"
      },
      "source": [
        "# ***Tracking User Interactions***\n",
        "\n",
        "We will create a function to log user interactions. Each interaction will be logged with the user ID, item ID, interaction type, and the group they belong to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92SRamL0yH4n",
        "outputId": "250c9acd-2933-428a-fa4d-bfbb180f9dd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User interactions logged and saved to 'interaction_log.csv'\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "# Function to simulate user interactions\n",
        "def log_interactions(num_interactions=1000):\n",
        "    interactions = []\n",
        "    for _ in range(num_interactions):\n",
        "        user_id = random.choice(np.concatenate((group_a, group_b)))\n",
        "        item_id = np.random.randint(1, 101)\n",
        "        interaction = np.random.choice(['view', 'click', 'purchase'], p=[0.7, 0.2, 0.1])\n",
        "        group = 'A' if user_id in group_a else 'B'\n",
        "        timestamp = datetime.now().isoformat()\n",
        "        interactions.append([user_id, item_id, interaction, group, timestamp])\n",
        "    return pd.DataFrame(interactions, columns=['user_id', 'item_id', 'interaction', 'group', 'timestamp'])\n",
        "\n",
        "interaction_log = log_interactions()\n",
        "interaction_log.to_csv('interaction_log.csv', index=False)\n",
        "print(\"User interactions logged and saved to 'interaction_log.csv'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKFVvhO7yNLP"
      },
      "source": [
        "# ***Analyzing Results***\n",
        "\n",
        "We will analyze the results to compare the performance of the different strategies. For simplicity, let's assume we are measuring the number of purchases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaXx0k-4ydOt",
        "outputId": "c4209285-9faa-4001-beaf-772b3ca5fab4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conversion Rates:\n",
            " interaction     click  purchase      view\n",
            "group                                    \n",
            "A            0.209213  0.097889  0.692898\n",
            "B            0.212944  0.100209  0.686848\n",
            "\n",
            "Chi-Square Test: chi2 = 0.0002803631690226361, p-value = 0.9866408062461679\n",
            "The difference in purchase rates between groups is not statistically significant.\n"
          ]
        }
      ],
      "source": [
        "# Load interaction log\n",
        "interaction_log = pd.read_csv('interaction_log.csv')\n",
        "\n",
        "# Analyze interactions by group\n",
        "grouped = interaction_log.groupby('group')['interaction'].value_counts().unstack().fillna(0)\n",
        "\n",
        "# Calculate conversion rates\n",
        "conversion_rates = grouped.apply(lambda x: x / x.sum(), axis=1)\n",
        "print(\"Conversion Rates:\\n\", conversion_rates)\n",
        "\n",
        "# Additional analysis can include statistical tests to determine significance\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Create a contingency table for purchase interactions\n",
        "contingency_table = pd.crosstab(interaction_log['group'], interaction_log['interaction'] == 'purchase')\n",
        "chi2, p, _, _ = chi2_contingency(contingency_table)\n",
        "\n",
        "print(f\"\\nChi-Square Test: chi2 = {chi2}, p-value = {p}\")\n",
        "if p < 0.05:\n",
        "    print(\"The difference in purchase rates between groups is statistically significant.\")\n",
        "else:\n",
        "    print(\"The difference in purchase rates between groups is not statistically significant.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5TsvQlPytz7"
      },
      "source": [
        "# ***Explanation***\n",
        "**A/B Test Setup:**\n",
        "\n",
        "assign_ab_groups function randomly assigns users to Group A or Group B based on the specified ratio.\n",
        "\n",
        "***Tracking User Interactions:***\n",
        "\n",
        "log_interactions function simulates user interactions, logging the user ID, item ID, interaction type, group, and timestamp.\n",
        "\n",
        "The interaction log is saved to a CSV file.\n",
        "\n",
        "***Analyzing Results:***\n",
        "\n",
        "Load the interaction log and group interactions by group.\n",
        "\n",
        "Calculate and print conversion rates for each group.\n",
        "\n",
        "Perform a Chi-Square test to determine if the difference in purchase rates between the groups is statistically significant.\n",
        "\n",
        "***This framework can be extended to include more sophisticated logging and analysis based on specific requirements and metrics relevant***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwIZaGYszmFh"
      },
      "source": [
        "# ***Mock API***\n",
        "\n",
        "To create mock APIs for simulating interactions with external services such as user data retrieval and product databases, you can use Flask to create simple APIs that return realistic data. Below is a solution for creating mock APIs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gko5cp0x0FCR"
      },
      "outputs": [],
      "source": [
        "pip install Flask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWYb4rQf0tGn"
      },
      "source": [
        "# ***Mock API Implementation***\n",
        "**app.py:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsDyOCC_0Mlm"
      },
      "source": [
        "# ***Create Flask App:***\n",
        "\n",
        "Create a new directory for your project.\n",
        "Inside the directory, create a file named app.py for the Flask application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvs_uNIA0r_q"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, jsonify, request\n",
        "import random\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Mock user data\n",
        "users = [\n",
        "    {\"user_id\": 1, \"name\": \"Alice\", \"age\": 30, \"location\": \"New York\"},\n",
        "    {\"user_id\": 2, \"name\": \"Bob\", \"age\": 25, \"location\": \"San Francisco\"},\n",
        "    {\"user_id\": 3, \"name\": \"Charlie\", \"age\": 35, \"location\": \"Chicago\"},\n",
        "    # Add more mock users as needed\n",
        "]\n",
        "\n",
        "# Mock product data\n",
        "products = [\n",
        "    {\"item_id\": 1, \"name\": \"Laptop\", \"category\": \"Electronics\", \"price\": 999.99},\n",
        "    {\"item_id\": 2, \"name\": \"Smartphone\", \"category\": \"Electronics\", \"price\": 499.99},\n",
        "    {\"item_id\": 3, \"name\": \"Book\", \"category\": \"Books\", \"price\": 19.99},\n",
        "    # Add more mock products as needed\n",
        "]\n",
        "\n",
        "# Mock user interactions\n",
        "interactions = []\n",
        "\n",
        "@app.route('/api/users/<int:user_id>', methods=['GET'])\n",
        "def get_user(user_id):\n",
        "    user = next((user for user in users if user[\"user_id\"] == user_id), None)\n",
        "    if user:\n",
        "        return jsonify(user)\n",
        "    else:\n",
        "        return jsonify({\"error\": \"User not found\"}), 404\n",
        "\n",
        "@app.route('/api/products/<int:item_id>', methods=['GET'])\n",
        "def get_product(item_id):\n",
        "    product = next((product for product in products if product[\"item_id\"] == item_id), None)\n",
        "    if product:\n",
        "        return jsonify(product)\n",
        "    else:\n",
        "        return jsonify({\"error\": \"Product not found\"}), 404\n",
        "\n",
        "@app.route('/api/interactions', methods=['POST'])\n",
        "def add_interaction():\n",
        "    interaction = request.json\n",
        "    interactions.append(interaction)\n",
        "    return jsonify(interaction), 201\n",
        "\n",
        "@app.route('/api/interactions', methods=['GET'])\n",
        "def get_interactions():\n",
        "    return jsonify(interactions)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spx8gdsX0V4h"
      },
      "source": [
        "# ***Explanation***\n",
        "**User Data Retrieval:**\n",
        "\n",
        "The endpoint /api/users/<int:user_id> retrieves user information by user ID.\n",
        "It searches for the user in the users list and returns the user's data in JSON format.\n",
        "\n",
        "**Product Data Retrieval:**\n",
        "\n",
        "The endpoint /api/products/<int:item_id> retrieves product information by item ID.\n",
        "\n",
        "It searches for the product in the products list and returns the product's data in JSON format.\n",
        "\n",
        "**Logging User Interactions:**\n",
        "\n",
        "The endpoint /api/interactions (POST) logs user interactions.\n",
        "It expects a JSON payload with interaction details and appends it to the interactions list.\n",
        "\n",
        "**Retrieving Logged Interactions:**\n",
        "\n",
        "The endpoint /api/interactions (GET) returns all logged interactions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icuXFePW1ImH"
      },
      "source": [
        "# ***Running the Flask App***\n",
        "\n",
        "Save the app.py file.\n",
        "\n",
        "In the terminal, navigate to the directory containing app.py.\n",
        "\n",
        "Run the Flask application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WUrGcoi3eBY"
      },
      "outputs": [],
      "source": [
        "python app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmFmpauF3kXw"
      },
      "source": [
        "# ***Testing the Mock APIs***\n",
        "You can test the mock APIs using tools like curl or Postman.\n",
        "\n",
        "**Example Requests:**\n",
        "\n",
        "*Get User Data:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cA160ZDk3pT_"
      },
      "outputs": [],
      "source": [
        "curl http://127.0.0.1:5000/api/users/1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flTofWKa3sUP"
      },
      "source": [
        "*Get Product Dat*a:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRu4VFbw3uLg"
      },
      "outputs": [],
      "source": [
        "curl http://127.0.0.1:5000/api/products/1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR6v2snl36o4"
      },
      "source": [
        "*Log User Interaction:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee24VfLG30w_"
      },
      "outputs": [],
      "source": [
        "curl -X POST -H \"Content-Type: application/json\" -d '{\"user_id\": 1, \"item_id\": 2, \"interaction\": \"view\"}' http://127.0.0.1:5000/api/interactions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6sXyDwK3-WY"
      },
      "source": [
        "*Get Logged Interactions:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vINWpkH32Nw"
      },
      "outputs": [],
      "source": [
        "curl http://127.0.0.1:5000/api/interactions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOx0f2364DuX"
      },
      "source": [
        "# ***These mock APIs provide data for testing your AI models and can be extended as needed for more complex scenarios.***"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "479fc16c96b64482afa5f3e533b3d90f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d2873467f744e5b90da2d5f43e17eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58bf6f0e547244e8be6faa0dd300de0d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d8b90d9e25641d9a712164aaed064a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c4c221749c44f1a96352dc1d1e6d15b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_479fc16c96b64482afa5f3e533b3d90f",
            "placeholder": "​",
            "style": "IPY_MODEL_ebf64c7ec1f64804b806784dbb234235",
            "value": "100%"
          }
        },
        "95f2c212fda74b4984112d7049d60cb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58bf6f0e547244e8be6faa0dd300de0d",
            "placeholder": "​",
            "style": "IPY_MODEL_4d2873467f744e5b90da2d5f43e17eb4",
            "value": " 30/30 [00:05&lt;00:00,  5.41it/s]"
          }
        },
        "b25f2833a42c4f38bb32dfe17331d11f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eab13da1d27b4381bfcf2eb31b00f013",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0d5c06b3d1d4b2787b55ec24a838258",
            "value": 30
          }
        },
        "c0d5c06b3d1d4b2787b55ec24a838258": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eab13da1d27b4381bfcf2eb31b00f013": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebf64c7ec1f64804b806784dbb234235": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efb878fa11b042fbbf61f177c3bc825e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c4c221749c44f1a96352dc1d1e6d15b",
              "IPY_MODEL_b25f2833a42c4f38bb32dfe17331d11f",
              "IPY_MODEL_95f2c212fda74b4984112d7049d60cb8"
            ],
            "layout": "IPY_MODEL_6d8b90d9e25641d9a712164aaed064a5"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
